source_dir: /Users/allwefantasy/projects/byzer-llm
target_file: /Users/allwefantasy/projects/byzer-llm/output.txt
urls: https://raw.githubusercontent.com/abetlen/llama-cpp-python/main/README.md

model: gpt3_5_chat
index_model: haiku_chat

skip_build_index: false
index_filter_level: 0

execute: true
auto_merge: true
human_as_model: true

query: >
  参考 README.md 以及 auto/__init__.py 文件， 重新实现 backend_llama_cpp.py 。  

